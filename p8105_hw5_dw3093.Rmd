---
title: "p8105_hw5_dw3093"
author: "Katherine Wang"
output: github_document
---

```{r include = FALSE, message = FALSE, warning = FALSE}
library(tidyverse)
library(rvest)
library(broom)
set.seed(1)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
  )
theme_set(theme_minimal()+ theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

#Question 1
```{r}
shared_bday <- function(n) {
  bday <- sample(1:365, size = n, replace = TRUE) 
  return(any(duplicated(bday)))
}
group_sizes <- 2:50
n_simulation <- 10000

prob <- numeric(length(group_sizes))
for (i in seq_along(group_sizes)) {
  group_size <- group_sizes[i]

  results <- replicate(n_simulation, shared_bday(group_size))
  prob[i] <- mean(results)
}
results <- data.frame(
  group_size = group_sizes,
  probability = prob
)

ggplot(results, aes(x = group_size, y = probability)) +
  geom_line() +
  geom_point(alpha=.6) +
  labs(
    title = "Probability of Shared Birthday as a Function of Group Size",
    x = "Group Size (n)",
    y = "Probability of Shared Birthday"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
  )
```
We can conclude that the probability of a shared birthday is low with small group sizes. However, as the group size increases, the probability rises sharply, reaching over 50% by around 23 people and approaching near certainty by 50 people. 


# Question 2
# Set up parameters as question required
```{r}
n <- 30
sigma <- 5
alpha <- 0.05
mu_values <- 0:6
n_simulations <- 5000
```

# Function to simulate data
```{r}
t_test <- function(mu) {
  sample_data <- rnorm(n = n, mean = mu, sd = sigma)
  t_stats <- t.test(sample_data, mu = 0) |>
    broom::tidy() |>
    select(estimate, p.value)
  return(t_stats)
}
```

# Generate simulation results for each mu value
```{r}
simulation_results <- tibble(
  mu = rep(mu_values, each = n_simulations)
) |>
  mutate(
    t_test_output = map(mu, t_test)
  ) |>
  unnest(cols = t_test_output)
```

# Calculate power and average estimates
```{r}
summary_results <- simulation_results |>
  group_by(mu) |>
  summarize(
    power = mean(p.value < alpha),
    avg_est_all = mean(estimate),
    avg_est_rej = mean(estimate[p.value < alpha], na.rm = TRUE),
    .groups = 'drop'
  )
```

# Plot 1: Power vs. True Value of μ
```{r}
ggplot(summary_results, aes(x = mu, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power of the t-test vs. True Value of μ",
    x = "True Value of μ",
    y = "Power (Proportion of Null Rejections)"
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
)
```

# Plot 2: Average Estimate vs. True Mean (mu)
```{r}
ggplot(summary_results, aes(x = mu)) +
  geom_line(aes(y = avg_est_all, color = "All Samples")) +
  geom_point(aes(y = avg_est_all, color = "All Samples")) +
  geom_line(aes(y = avg_est_rej, color = "Null Rejected Samples")) +
  geom_point(aes(y = avg_est_rej, color = "Null Rejected Samples")) +
  labs(
    title = "Average Estimate of Sample Mean (μ̂) vs. True Mean (μ)",
    x = "True Mean (μ)",
    y = "Average Estimate of Sample Mean (μ̂)",
    color = "Sample Type"
  ) +
  scale_color_manual(
    values = c("All Samples" = "orange", "Null Rejected Samples" = "pink"),
    labels = c("All Samples", "Null Rejected Samples")
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold")
)
```
# Question 3
#Load dataset from github
```{r}
homicide = read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv")
summary(homicide)
```
This dataset contains `r nrow(homicide)` records on homicide incidents, each with `r ncol(homicide)` columns. 
Each entry includes a unique identifier (uid), report date (reported_date), and victim details such as last name (victim_last), first name (victim_first), race (victim_race), age (victim_age), and sex (victim_sex). Location is specified by city, state, and geographic coordinates (lat and lon). The (disposition) shows the case outcome.

# Create city_state variable and summarize
```{r}
homicide_sum <- homicide %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  group_by(city_state) %>%
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest")),
    .groups = 'drop'
  ) %>% 
  filter(city_state!="Tulsa, AL")

knitr::kable(homicide_sum)
```

```{r}
baltimore_data <- homicide_sum %>%
  filter(city_state == "Baltimore, MD")

baltimore_test <- prop.test(
  x = baltimore_data$unsolved_homicides,
  n = baltimore_data$total_homicides
) %>%
  broom::tidy()

baltimore_result <- baltimore_test %>% 
  select(estimate, conf.low, conf.high) %>%
  mutate(city_state = "Baltimore, MD")

knitr::kable(baltimore_result, 
             col.names = c("Estimate", "Lower CI", "Upper CI", "City, State"))
```
```{r}
unsolved_p <- function(unsolved, total){
  prop_test_result <- prop.test(unsolved, total)
  broom::tidy(prop_test_result) %>% 
    select(estimate, conf.low, conf.high)
}
homicide_sum <- homicide_sum %>% 
  mutate(
    prop_results = purrr::map2(unsolved_homicides, 
                               total_homicides, 
                               ~unsolved_p(.x, .y)
                               )
  ) %>%
  unnest(prop_results)

knitr::kable(homicide_sum)
```

```{r}
homicide_sum |>
mutate(
    city_state = reorder(city_state, estimate)
  )|>
ggplot(aes(x = city_state, y = estimate)) +
  geom_point(color = "pink") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    x = "City, State",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.text = element_text(size = 8),
    plot.title = element_text(hjust = 0.5, face = "bold")
  )
```

